{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "################################### CITI-ACDS Python Boot Camp summer 2021 - MINI PROJECT #################################\n",
    "# Multiclass Classification of construction contract text into 3 categories: Design, COnstruction and O&M\n",
    "# Name: Fahad UL Hassan\n",
    "# CUID: C13169182\n",
    "\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "import logging\n",
    "import nltk\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from numpy import random\n",
    "from itertools import islice\n",
    "from functools import reduce\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn import utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from nltk import pos_tag\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from functools import reduce\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "np.random.seed(1056)\n",
    "\n",
    "## hide warnings##\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the csv file\n",
    "Dataset = pd.read_csv('data_miniproject.csv')\n",
    "Types_List = ['O&M','Design','Construction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################preprocessing#######################\n",
    "\n",
    "#lowerCase\n",
    "def LowerCase(data):\n",
    "    data['Requirement'] = data['Requirement'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "def RemovePunctuation (data):\n",
    "    data['Requirement'] = data['Requirement'].str.replace('[^\\w\\s]','')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POSTagging (data):\n",
    "    tagged_data = data['Requirement'].str.split().map(pos_tag)\n",
    "    tagged_data.head()\n",
    "#    print(tagged_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "def RemoveStopWords (data):\n",
    "    stop = stopwords.words('english')\n",
    "    data['Requirement'] = data['Requirement'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrectSpelling (data):\n",
    "    data['Requirement'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove common frequent words\n",
    "def RemoveFrequentWords (data, topFrequentNumber=10):\n",
    "    mask = data.Type.apply(lambda x: 'Design' in x)\n",
    "    FrequentDesign= pd.Series(' '.join(data[mask]['Requirement']).split()).value_counts()[:topFrequentNumber]\n",
    "    mask = data.Type.apply(lambda x: 'O&M' in x)\n",
    "    FrequentOM= pd.Series(' '.join(data[mask]['Requirement']).split()).value_counts()[:topFrequentNumber]\n",
    "    mask = data.Type.apply(lambda x: 'Construction' in x)\n",
    "    FrequentConstruction= pd.Series(' '.join(data[mask]['Requirement']).split()).value_counts()[:topFrequentNumber]\n",
    "    allFrequent=[list(FrequentDesign.index),FrequentOM.index.tolist(),FrequentConstruction.index.tolist()]\n",
    "    commonFrequent=list(reduce(set.intersection, [set(item) for item in allFrequent ]))\n",
    "    data['Requirement'] = data['Requirement'].apply(lambda x: \" \".join(x for x in x.split() if x not in commonFrequent))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveUniqueWords (data):\n",
    "    counts= pd.Series(' '.join(data['Requirement']).split()).value_counts()\n",
    "    to_remove = counts[counts <= 1].index\n",
    "    data['Requirement'] = data['Requirement'].apply(lambda x: \" \".join(x for x in x.split() if x not in to_remove))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddTokens (data):\n",
    "    data['Tokens'] = data['Requirement'].apply(lambda x: TextBlob(x).words)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stem(data):\n",
    "    st = PorterStemmer()\n",
    "    data['Requirement'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lemmatize(data):\n",
    "    data['Requirement'] = data['Requirement'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalanceData(data,numberofsamples=600):\n",
    "    data=data.groupby('Type').apply(lambda x: x.sample(numberofsamples)).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTFIDF(data,maxNGramRange=1):\n",
    "    tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "    stop_words= 'english',ngram_range=(1,maxNGramRange),sublinear_tf=True)\n",
    "    Dataset_vect = tfidf.fit_transform(Dataset['Requirement'])\n",
    "##    idf = tfidf.idf_\n",
    "##    print(dict(zip(tfidf.get_feature_names(), idf)))\n",
    "    return Dataset_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBagOfWords(data,maxNGramRange=1):\n",
    "    bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,maxNGramRange),analyzer = \"word\")\n",
    "    Dataset_bow = bow.fit_transform(data['Requirement'])\n",
    "    return Dataset_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveNonAlphabet(data):\n",
    "\tdata['Requirement'] = data['Requirement'].str.replace('[^0-9a-z #+_]','')\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "#Dataset=Stem(Dataset)\n",
    "Dataset=Lemmatize(Dataset)\n",
    "Dataset= LowerCase(Dataset)\n",
    "Dataset=RemovePunctuation(Dataset)\n",
    "#Dataset=POSTagging(Dataset)\n",
    "Dataset=RemoveStopWords(Dataset)\n",
    "#Dataset=RemoveFrequentWords(Dataset,50)\n",
    "Dataset=RemoveNonAlphabet(Dataset)\n",
    "#Dataset=RemoveUniqueWords(Dataset)\n",
    "Dataset=AddTokens(Dataset)\n",
    "tfidf= GetTFIDF(Dataset,1)\n",
    "bow= GetBagOfWords(Dataset,2)\n",
    "#Dataset=BalanceData(Dataset,400)\n",
    "#################################\n",
    "#print(Dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################preprocessing########################################\n",
    "Dataset['Requirement'].apply(lambda x: len(x.split(' '))).sum()\n",
    "\n",
    "X = Dataset.Requirement\n",
    "y = Dataset.Type\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 49)\n",
    "################################# End of preprocessing########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################## NAIVE BIAS ########################\n",
      "accuracy 0.8697850821744627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         O&M       0.75      0.84      0.80       185\n",
      "      Design       0.88      0.91      0.90       413\n",
      "Construction       0.98      0.81      0.89       193\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       791\n",
      "   macro avg       0.87      0.85      0.86       791\n",
      "weighted avg       0.88      0.87      0.87       791\n",
      "\n",
      "[[156  28   1]\n",
      " [ 36 375   2]\n",
      " [ 15  21 157]]\n",
      "############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################## NAIVE BAYESIAN ########################\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"######################## NAIVE BAYESIAN ########################\")\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=Types_List))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"############################################################\\n\\n\")\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Linear Support Vector Machine ###############\n",
      "accuracy 0.8874841972187105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         O&M       0.79      0.85      0.82       185\n",
      "      Design       0.90      0.92      0.91       413\n",
      "Construction       0.98      0.86      0.92       193\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       791\n",
      "   macro avg       0.89      0.88      0.88       791\n",
      "weighted avg       0.89      0.89      0.89       791\n",
      "\n",
      "[[158  25   2]\n",
      " [ 34 378   1]\n",
      " [  8  19 166]]\n",
      "#############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################## Linear Support Vector Machines################################\n",
    "from sklearn.linear_model import SGDClassifier      \n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print(\"############### Linear Support Vector Machine ###############\")\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=Types_List))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"#############################################################\\n\\n\")\n",
    "#############################################################  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Logistic Regression #####################\n",
      "accuracy 0.8735777496839444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         O&M       0.76      0.79      0.78       185\n",
      "      Design       0.89      0.91      0.90       413\n",
      "Construction       0.96      0.88      0.92       193\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       791\n",
      "   macro avg       0.87      0.86      0.86       791\n",
      "weighted avg       0.88      0.87      0.87       791\n",
      "\n",
      "[[147  33   5]\n",
      " [ 36 375   2]\n",
      " [ 11  13 169]]\n",
      "###############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################LogisticRegression######################################\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', LogisticRegression(n_jobs=1, C=1e5)),])\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"##################### Logistic Regression #####################\")\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=Types_List))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"###############################################################\\n\\n\")\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Decision Tree ###############\n",
      "Accuracy score (training): 0.998\n",
      "Accuracy score (validation): 0.823\n",
      "accuracy 0.8230088495575221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         O&M       0.76      0.73      0.74       185\n",
      "      Design       0.83      0.89      0.86       413\n",
      "Construction       0.88      0.76      0.82       193\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       791\n",
      "   macro avg       0.82      0.79      0.81       791\n",
      "weighted avg       0.82      0.82      0.82       791\n",
      "\n",
      "[[135  41   9]\n",
      " [ 33 369  11]\n",
      " [ 10  36 147]]\n",
      "#############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################## Decision Tree ########################################\n",
    "dt = Pipeline([('vect', CountVectorizer()),('clf', tree.DecisionTreeClassifier())])\n",
    "#dt = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', tree.DecisionTreeClassifier())])\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"############### Decision Tree ###############\")\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(dt.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(dt.score(X_test, y_test)))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=Types_List))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"#############################################################\\n\\n\")\n",
    "#############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### KNeighborsClassifier ###############\n",
      "accuracy 0.8508217446270544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         O&M       0.71      0.81      0.76       185\n",
      "      Design       0.89      0.88      0.89       413\n",
      "Construction       0.91      0.82      0.87       193\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       791\n",
      "   macro avg       0.84      0.84      0.84       791\n",
      "weighted avg       0.86      0.85      0.85       791\n",
      "\n",
      "[[149  29   7]\n",
      " [ 40 365   8]\n",
      " [ 20  14 159]]\n",
      "#############################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################KNeighborsClassifier####################################\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "############### KNeighborsClassifier ###############\n",
    "knn = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', KNeighborsClassifier(n_neighbors=5))])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"############### KNeighborsClassifier ###############\")\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=Types_List))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"#############################################################\\n\\n\")\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.998\n",
      "Accuracy score (validation): 0.870\n",
      "accuracy 0.8697850821744627\n",
      "Confusion Matrix:\n",
      "[[145  36   4]\n",
      " [ 21 389   3]\n",
      " [  9  30 154]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Construction       0.83      0.78      0.81       185\n",
      "      Design       0.85      0.94      0.90       413\n",
      "         O&M       0.96      0.80      0.87       193\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       791\n",
      "   macro avg       0.88      0.84      0.86       791\n",
      "weighted avg       0.87      0.87      0.87       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################RandomForestClassifier#########################################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = Pipeline([('vect', CountVectorizer()),('clf', RandomForestClassifier(n_estimators=1500, max_depth=None, min_samples_split=2, random_state=0))])\n",
    "#rf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', RandomForestClassifier(n_estimators=1500, max_depth=None, min_samples_split=2, random_state=0))])\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "print('accuracy %s' % accuracy_score(predictions, y_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.998\n",
      "Accuracy score (validation): 0.841\n",
      "accuracy 0.8407079646017699\n",
      "Confusion Matrix:\n",
      "[[137  37  11]\n",
      " [ 27 376  10]\n",
      " [  7  34 152]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Construction       0.80      0.74      0.77       185\n",
      "      Design       0.84      0.91      0.87       413\n",
      "         O&M       0.88      0.79      0.83       193\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       791\n",
      "   macro avg       0.84      0.81      0.82       791\n",
      "weighted avg       0.84      0.84      0.84       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################BaggingClassifier##############################################\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "bagging = Pipeline([('vect', CountVectorizer()),('clf', BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7))])\n",
    "#bagging = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7))])\n",
    "eclf = bagging.fit(X_train, y_train)\n",
    "predictions = eclf.predict(X_test)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(eclf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(eclf.score(X_test, y_test)))\n",
    "print('accuracy %s' % accuracy_score(predictions, y_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n",
    "##############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.962\n",
      "Accuracy score (validation): 0.875\n",
      "accuracy 0.8748419721871049\n",
      "Confusion Matrix:\n",
      "[[153  26   6]\n",
      " [ 29 379   5]\n",
      " [  7  26 160]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Construction       0.81      0.83      0.82       185\n",
      "      Design       0.88      0.92      0.90       413\n",
      "         O&M       0.94      0.83      0.88       193\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       791\n",
      "   macro avg       0.87      0.86      0.87       791\n",
      "weighted avg       0.88      0.87      0.87       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################XGBOOST#########################################\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "# Create adaboost classifer object\n",
    "abc = Pipeline([('vect', CountVectorizer()),('clf', XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.5, max_depth = 5, alpha = 10, n_estimators = 50))])\n",
    "#abc = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', XGBClassifier(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 500))])\n",
    "# Train XGboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(abc.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(abc.score(X_test, y_test)))\n",
    "print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1658 samples, validate on 185 samples\n",
      "Epoch 1/6\n",
      "1658/1658 [==============================] - ETA: 6s - loss: 1.1052 - acc: 0.414 - ETA: 1s - loss: 1.0496 - acc: 0.490 - ETA: 0s - loss: 1.0005 - acc: 0.517 - ETA: 0s - loss: 0.9423 - acc: 0.560 - ETA: 0s - loss: 0.8934 - acc: 0.592 - 1s 377us/step - loss: 0.8615 - acc: 0.6092 - val_loss: 0.6560 - val_acc: 0.7243\n",
      "Epoch 2/6\n",
      "1658/1658 [==============================] - ETA: 0s - loss: 0.6708 - acc: 0.785 - ETA: 0s - loss: 0.5755 - acc: 0.819 - ETA: 0s - loss: 0.5485 - acc: 0.829 - ETA: 0s - loss: 0.5163 - acc: 0.841 - ETA: 0s - loss: 0.5021 - acc: 0.847 - 0s 180us/step - loss: 0.4874 - acc: 0.8480 - val_loss: 0.4610 - val_acc: 0.8108\n",
      "Epoch 3/6\n",
      "1658/1658 [==============================] - ETA: 0s - loss: 0.3314 - acc: 0.885 - ETA: 0s - loss: 0.3514 - acc: 0.885 - ETA: 0s - loss: 0.3369 - acc: 0.893 - ETA: 0s - loss: 0.3235 - acc: 0.900 - ETA: 0s - loss: 0.3202 - acc: 0.901 - 0s 168us/step - loss: 0.3190 - acc: 0.9017 - val_loss: 0.3902 - val_acc: 0.8270\n",
      "Epoch 4/6\n",
      "1658/1658 [==============================] - ETA: 0s - loss: 0.3399 - acc: 0.885 - ETA: 0s - loss: 0.2829 - acc: 0.922 - ETA: 0s - loss: 0.2432 - acc: 0.934 - ETA: 0s - loss: 0.2481 - acc: 0.931 - ETA: 0s - loss: 0.2402 - acc: 0.930 - 0s 172us/step - loss: 0.2349 - acc: 0.9337 - val_loss: 0.3590 - val_acc: 0.8486\n",
      "Epoch 5/6\n",
      "1658/1658 [==============================] - ETA: 0s - loss: 0.1601 - acc: 0.971 - ETA: 0s - loss: 0.1676 - acc: 0.971 - ETA: 0s - loss: 0.1822 - acc: 0.958 - ETA: 0s - loss: 0.1726 - acc: 0.957 - ETA: 0s - loss: 0.1800 - acc: 0.950 - 0s 164us/step - loss: 0.1806 - acc: 0.9487 - val_loss: 0.3552 - val_acc: 0.8432\n",
      "Epoch 6/6\n",
      "1658/1658 [==============================] - ETA: 0s - loss: 0.1473 - acc: 0.942 - ETA: 0s - loss: 0.1355 - acc: 0.968 - ETA: 0s - loss: 0.1462 - acc: 0.962 - ETA: 0s - loss: 0.1451 - acc: 0.961 - ETA: 0s - loss: 0.1441 - acc: 0.959 - 0s 185us/step - loss: 0.1422 - acc: 0.9614 - val_loss: 0.3500 - val_acc: 0.8378\n",
      "791/791 [==============================] - ETA:  - 0s 35us/step\n",
      "Test accuracy: 0.8887484131661136\n",
      "791/791 [==============================] - ETA:  - ETA:  - 0s 90us/step\n",
      "Test set\n",
      "  Loss: 0.288\n",
      "  Accuracy: 0.889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Design       0.82      0.89      0.85       200\n",
      "Construction       0.91      0.90      0.91       389\n",
      "         O&M       0.92      0.87      0.89       202\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       791\n",
      "   macro avg       0.88      0.89      0.88       791\n",
      "weighted avg       0.89      0.89      0.89       791\n",
      "\n",
      "[[178  15   7]\n",
      " [ 31 349   9]\n",
      " [  8  18 176]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VPW9//HXJ/sKZMVAyMKOAoJGFAGLuIFa1NpSF6rWhd5b7fXnve2t3l9rW3vvrb9uLq31FizV1iq1WpVWel1YBEWEUKGyZ2FJCJCQkH2d5PP740xgEhIzgSSTmfk8H495zMxZvwfxfb58z5nPEVXFGGNMcAjxdQOMMcYMHAt9Y4wJIhb6xhgTRCz0jTEmiFjoG2NMELHQN8aYIGKhb4wxQcRC3wQMEVknIidEJNLXbTFmsLLQNwFBRLKAOYACCwdwv2EDtS9j+oKFvgkUdwCbgOeBO9sniki0iPxMRA6KSJWIfCAi0e55s0Vko4hUikiRiNzlnr5ORO712MZdIvKBx3cVkftFJA/Ic097yr2NahHZKiJzPJYPFZH/EJECEalxzx8lIs+IyM88D0JE/iIi/6c//oCMAQt9EzjuAP7gfl0jIsPd038KXAhcCiQC/w60iUgG8DfgF0AKMA3Y1ov93QhcDJzr/r7FvY1E4CXgTyIS5Z73r8CtwLXAEOBuoB54AbhVREIARCQZuAJ4uTcHbkxvWOgbvycis4FM4BVV3QoUALe5w/Ru4EFVPayqraq6UVWbgNuB91T1ZVVtUdVyVe1N6P9IVStUtQFAVV90b8Olqj8DIoEJ7mXvBb6jqnvVsd297GagCifoAW4B1qnqsbP8IzGmWxb6JhDcCbyjqsfd319yT0sGonBOAp2N6ma6t4o8v4jIv4nIbvcQUiUw1L3/nvb1ArDY/Xkx8PuzaJMxPbKLUMavucfnFwGhInLUPTkSGAakAY3AGGB7p1WLgBndbLYOiPH4fk4Xy5wsT+sev/82To99p6q2icgJQDz2NQbY0cV2XgR2iMj5wCTgjW7aZEyfsJ6+8Xc3Aq04Y+vT3K9JwAaccf7lwM9FZIT7gupM9y2dfwCuFJFFIhImIkkiMs29zW3AF0QkRkTGAvf00IZ4wAWUAWEi8ijO2H2754Afisg4cUwVkSQAVS3GuR7we+C19uEiY/qLhb7xd3cCv1XVQ6p6tP0F/BJn3P5h4FOcYK0A/h8QoqqHcC6s/pt7+jbgfPc2nwCagWM4wy9/6KENb+NcFN4HHMT514Xn8M/PgVeAd4Bq4DdAtMf8F4Ap2NCOGQBiD1ExxrdE5DKcYZ4sVW3zdXtMYLOevjE+JCLhwIPAcxb4ZiBY6BvjIyIyCajEueD8pI+bY4KEDe8YY0wQsZ6+McYEkUF3n35ycrJmZWX5uhnGGONXtm7delxVU3pabtCFflZWFrm5ub5uhjHG+BUROejNcja8Y4wxQcRC3xhjgoiFvjHGBJFBN6bflZaWFoqLi2lsbPR1U/pdVFQU6enphIeH+7opxpgA5BehX1xcTHx8PFlZWYhIzyv4KVWlvLyc4uJisrOzfd0cY0wA8ovhncbGRpKSkgI68AFEhKSkpKD4F40xxjf8IvSBgA/8dsFynMYY3/CL4R1jjAk0bW1KWW0ThysbKHG/YiPDuP3izH7dr4W+lyorK3nppZf4+te/3qv1rr32Wl566SWGDRvWTy0zxgxGtU0uSiobOoR6SWUjhysbOFLVwNGqRlpaO9Y+m54xzEJ/sKisrORXv/rVaaHf2tpKaGhot+utWrWqv5tmjBlgrtY2jtU0nQzz9mA/4g71ksoGqhtdHdYJDRHOGRLFiGFRXJCRwIhh0YwYFs3IYVEnPw+J6v+79iz0vfTwww9TUFDAtGnTCA8PJy4ujrS0NLZt28auXbu48cYbKSoqorGxkQcffJAlS5YAp8pK1NbWsmDBAmbPns3GjRsZOXIkb775JtHR0T3s2RgzkFSV6gbXqSCvauBwZaNHb72Bo9WNtHUqUDw0OpwRw6JJT4hmRnbiaaGeGh9FaIjvr9l5FfoiMh94CgjFedjD453mZ+I8izQF59Fzi93P/kREWnEeVwdwSFUXnk2Df/CXnewqqT6bTZzm3BFD+N7nz/vMZR5//HF27NjBtm3bWLduHddddx07duw4eWvl8uXLSUxMpKGhgYsuuoibb76ZpKSkDtvIy8vj5ZdfZtmyZSxatIjXXnuNxYsX9+mxGGM+W7OrjWPVjR2GXTqHel1za4d1wkOFtKHRjBgWxSVjkhjpDvT2UE8bGk1spH/0oXtspYiEAs8AVwHFwBYRWamquzwW+ynwO1V9QUTmAT8CvuKe16Cq0wgwM2bM6HAv/dNPP83rr78OQFFREXl5eaeFfnZ2NtOmOX8UF154IQcOHBiw9hoTDFSVE/Ut3Y6ll1Q2UFbbROfHiCTFRjBiWDSjU2KZPS65Q6iPGBpFclwkIYOgl94XvDk1zQDyVbUQQERWADcAnqF/LvCQ+/Na4I2+bKSnnnrkAyU2Nvbk53Xr1vHee+/x0UcfERMTw9y5c7u81z4yMvLk59DQUBoaGgakrcYEisaWVo5UNXYZ6iWVDZRUNdDY0vGpk5FhISdDfO6EFHeQt4e6M/QSFd79dblA403ojwSKPL4XAxd3WmY7cDPOENBNQLyIJKlqORAlIrmAC3hcVfvthNCf4uPjqamp6XJeVVUVCQkJxMTEsGfPHjZt2jTArTMmMNQ3uzhUUc+B4/UUn6h37nSpbKSkygn347XNp62TGh/JiGHRTEobwryJqR7DLk6oJ8ZG2O9fPHgT+l39aXV+xuI3gV+KyF3AeuAwTsgDZKhqiYiMBtaIyKeqWtBhByJLgCUAGRkZvWj+wElKSmLWrFlMnjyZ6Ohohg8ffnLe/Pnz+Z//+R+mTp3KhAkTuOSSS3zYUmMGt6r6Fg5W1HGgvJ5D5e3v9Rwor6O0pqnDsjERoSd76eeNGOLRQ3dCffjQSCLDgqeX3hd6fEauiMwEvq+q17i/PwKgqj/qZvk4YI+qpncx73ngr6r6anf7y8nJ0c4PUdm9ezeTJk367CMJIMF2vCawqDo/OnKC/FSwH6yo52B5HZX1LR2WHz4kkszEWDKTYtwv53NGYgxDo8Otl+4lEdmqqjk9LedNT38LME5EsnF68LcAt3XaWTJQoaptwCM4d/IgIglAvao2uZeZBfy4V0dijBl0WtuUo9WNHDzeHuh1HDx+KtjrPe5+CREYmRBNZmIs101JOy3YYyL8466XQNHjn7aqukTkAeBtnFs2l6vqThF5DMhV1ZXAXOBHIqI4wzv3u1efBPxaRNpw6vw83umuH2PMINXsauNwZQMHyus4eLzOHehOqBdVNNDceuqCaURoCOmJ0WQlxXLJ6EQyE2PITI4lMzGG9IQYIsL8psxXwPPqFKuqq4BVnaY96vH5VeC0IRtV3QhMOcs2GmP6SUNzq3PhtLyOg+V17lB3eu6HTzR0+AFSTEQoGYkxjEuN58pJw8lMiiUrKYaMpBjShkYPih8emZ7Zv6uMCXBVDS0nL5Q6d8bUnQz2Y9UdL5wOiwknMzGG6aMSuHHayA7BnhIXaePrAcBC3xg/p6ocr23mUEUdBzzG1dsvop7odOE0JT6SrKQY5oxL6TAMk5kUw7CYCB8dhRkoFvrG+IG2NuVIdWPHIRiPYK/rdOE0bWg0WckxLJiS5g70UxdO/aVcgOkf9l/fS2daWhngySefZMmSJcTExPRDy0wgUlUKj9exdk8pq3eXsvXQCZpdpy6chocKoxKc3vnF2YlkJsWQlRRLRlIM6QnRdu+66ZaFvpe6K63sjSeffJLFixdb6JvP1OxqY/P+ClbvOcbaPaUcKK8HYPzwOBZfnMmY1NiT97OPGGYXTs2ZsdD3kmdp5auuuorU1FReeeUVmpqauOmmm/jBD35AXV0dixYtori4mNbWVr773e9y7NgxSkpKuPzyy0lOTmbt2rW+PhQziJTWNLJuTxlr9pSyIa+MuuZWIsJCuHRMEnfPzubyCamMSrTOguk7/hf6f3sYjn7a83K9cc4UWPD4Zy7iWVr5nXfe4dVXX2Xz5s2oKgsXLmT9+vWUlZUxYsQI3nrrLcCpyTN06FB+/vOfs3btWpKTk/u23cbvtLUpO0qqWL27lLV7S/lHcRUA5wyJYuG0kVwxMZVLxybZD5ZMv7G/WWfgnXfe4Z133mH69OkA1NbWkpeXx5w5c/jmN7/Jt7/9ba6//nrmzJnj45aawaC2ycUHeU5vfu3eMspqmhCB6aOG8c2rx3P5xFTOTRtit0OaAeF/od9Dj3wgqCqPPPIIX/va106bt3XrVlatWsUjjzzC1VdfzaOPPtrFFkygO3C8jjV7Slmzp5SP95fT0qrER4Vx2fgUrpiYyufGp5AUF9nzhozpY/4X+j7iWVr5mmuu4bvf/S633347cXFxHD58mPDwcFwuF4mJiSxevJi4uDief/75Duva8E7gana1kXugwgn6vaUUltUBMDY1jq/OymbexFQuzEwgPNTKERjfstD3kmdp5QULFnDbbbcxc+ZMAOLi4njxxRfJz8/nW9/6FiEhIYSHh/Pss88CsGTJEhYsWEBaWppdyA0gx2ubWLe3jDV7jrFh33FqmlxEhIZw8ehE7rgkk3kTh5ORZBdhzeDSY2nlgWallYPveP2FqrKzpPrksM324kpUnYd4zJuYyryJqcwam2w/fjI+0ZellY0JWnVNLj7MP+6+CFvKsWrnIuzU9GE8dOV45k1M5bwRdhHW+A8LfWM6OVRez5o9x1izt4xNBeU0t7YRHxnGnPHJXD4hlbkTUkmJt4uwxj/5TeiralD0pgbbcFswaGltY+vBE07Jgz2l5JfWAjA6OZY7ZmYyb2IqOVmJVhPeBAS/CP2oqCjKy8tJSkoK6OBXVcrLy4mKivJ1UwJeRV0z7+9z6tqs31dGdaOL8FDh4uwkbpuRwbyJqWQlx/q6mcb0Ob8I/fT0dIqLiykrK/N1U/pdVFQU6emnPV7YnCVVZfeRGtbuLWX17mN8UuRchE2Oi2T+5HOYNzGV2eNSiLOLsCbA+cXf8PDwcLKzs33dDONnGppb2VhwnNV7Slm7p5QjVY0ATE0fyoNXjGPexFQmjxhKiBUuM0HEL0LfGG8Vn6hnrfuWyo0F5TS52oiNCGXOuBQeujKVuRNTSI234TMTvCz0jV9ztbbxSVGlU8BsTyl7jzm/ms5KiuG2izO4YuJwLspOsPryxrh5FfoiMh94CggFnlPVxzvNzwSWAylABbBYVYvd8+4EvuNe9D9V9YU+arsJUpX1zby/zylgtm5vGVUNLYSFCDOyE/lOziTmTUxldEqcr5tpzKDUY+iLSCjwDHAVUAxsEZGVqrrLY7GfAr9T1RdEZB7wI+ArIpIIfA/IARTY6l73RF8fiAl8hWW1/HJNPm9uL6G1TUmKjeCqc4e7L8ImMyQq3NdNNGbQ86anPwPIV9VCABFZAdwAeIb+ucBD7s9rgTfcn68B3lXVCve67wLzgZfPvukmWOSX1vCLNfn8ZXsJkWGh3Dkzi4XTRjB1pF2ENaa3vAn9kUCRx/di4OJOy2wHbsYZAroJiBeRpG7WHdl5ByKyBFgCkJGR4W3bTYDbd6yGp1fn8danR4gOD+W+y0Zz35zRJFtJYmPOmDeh31VXqvPPRr8J/FJE7gLWA4cBl5froqpLgaXgFFzzok0mgO05Ws0vVuezascRYsJD+efPjeHeOaNJjI3wddOM8XvehH4xMMrjezpQ4rmAqpYAXwAQkTjgZlWtEpFiYG6nddedRXtNANtVUs3Tq/P4351HiYsM4/65Y7lndjYJFvbG9BlvQn8LME5EsnF68LcAt3kuICLJQIWqtgGP4NzJA/A28N8ikuD+frV7vjEn7ThcxVOr83h31zHio8L4lyvGcc+sbIbG2IVZY/paj6Gvqi4ReQAnwEOB5aq6U0QeA3JVdSVOb/5HIqI4wzv3u9etEJEf4pw4AB5rv6hrzD+KK3l6dR7v7S5lSFQYD105nrtmZTE02sLemP7iFw9RMYFlW1ElT723j7V7yxgaHc69s7O5c1aW3XJpzFmwh6iYQWfrwRM8tTqP9fvKSIgJ51vXTOCOmZnEW9gbM2As9E2/yz1QwVOr89iQd5zE2AgeXjCRr1ySaY8VNMYH7P86028+LiznqdV5bCwoJzkugv+4diKLL8kkJsL+2hnjK/Z/n+lTqspHheU8vTqPTYUVpMRH8p3rJnH7xZlER1jRM2N8zULf9AlVZWNBOU+9l8fmAxWkxkfyvc+fy60zMogKt7A3ZrCw0DdnRVXZkHecp1fnkXvwBOcMieIHC8/jyxeNsrA3ZhCy0DdnRFV5f18ZT63O45NDlYwYGsUPb5zMopx0q11vzCBmoW96RVVZu7eUp1bns72okpHDovmvmybzxQst7I3xBxb6xiuqynu7S3l6dR6fHq4iPSGax78whS9ckE5EWIivm2eM8ZKFvvlMbW3Ku7uP8fTqPHaWVJOZFMOPvziVm6aPJDzUwt4Yf2Ohb7rU1qa8vfMoT63OY8/RGrKSYvjpl87nxmkjCLOwN8ZvWeibDtralFU7jvCL1fnsPVbD6JRYnvjy+Xx+qoW9MYHAQt8A0NqmvPXpEX6xOo+80lrGpMTy1C3TuH7qCELtkYTGBAwL/SDX2qb8ZXsJv1iTR0FZHeOHx/GLW6dz7ZQ0C3tjApCFfpBytbaxcnsJv1yTT+HxOiaeE8+vbr+A+eedYw8bNyaAWegHmZbWNt745DDPrM3nQHk9k9KG8D+LL+Dqcy3sjQkGFvpBoqW1jT//vZhn1hZwqKKe80YMYelXLuSqc4cjYmFvTLCw0A9wza42Xvt7Mc+szaf4RANT04fyvc/nMG9iqoW9MUHIQj9ANbla+VNuMc+uK+BwZQPnjxrGD2+YzNwJKRb2xgQxr0JfROYDT+E8GP05VX280/wM4AVgmHuZh1V1lYhkAbuBve5FN6nqP/VN001XGltaeSW3iGfXFXCkqpELMobx31+YwmXjki3sjTE9h76IhALPAFcBxcAWEVmpqrs8FvsO8IqqPisi5wKrgCz3vAJVnda3zTadNba0smLzIZ59v4Bj1U1clJXAT754PrPGJlnYG2NO8qanPwPIV9VCABFZAdwAeIa+AkPcn4cCJX3ZSNO9xpZW/vDxIX79fgGlNU3MyE7kiUXTmDnGwj5g1JZC5SEIj4aIOIiMh4hYCIv0dcuMH/Im9EcCRR7fi4GLOy3zfeAdEfkGEAtc6TEvW0Q+AaqB76jqhs47EJElwBKAjIwMrxsf7A5XNvCFX33IseomZo5O4ulbp3PJ6CRfN8ucjZpjcGQblGw79V7TTR8qJBwi4yDCfRKIjHOfFLqa5v7e5fx4591OIkHBm9Dvqruonb7fCjyvqj8TkZnA70VkMnAEyFDVchG5EHhDRM5T1eoOG1NdCiwFyMnJ6bxt041l6wupqGvm5fsuYeYYC3u/U3O0Y7gf2QY1R9wzBZLHQdZsGDENEseAqwGa66CpFppr3O910FwLTTXOe3Ots13PaW0u79oTEu4+EcR7nBxiPU4acaefKCJiPT7HnXqPcJ9E7F+bg443oV8MjPL4ns7pwzf3APMBVPUjEYkCklW1FGhyT98qIgXAeCD3bBse7Crrm3klt4iF54+0wPcH1UdO78HXHnXPFEgeD9mXQdo0J+TPmeIEbV9wNZ06UfR40uhifm1px/Vbm73bb0jYqRNAVyeFrj53Oa19OCvKTiJ9wJvQ3wKME5Fs4DBwC3Bbp2UOAVcAz4vIJCAKKBORFKBCVVtFZDQwDijss9YHsT98fIj65lbuuyzb100xnlSd3nrnHnztMWe+hDgBP3quE+5p7QEf139tCot0XrF91DlwNXucKLw4aXSeX1vWcX5rk3f7ldAzGLr6jPnh0UF5Eukx9FXVJSIPAG/j3I65XFV3ishjQK6qrgT+DVgmIg/hDP3cpaoqIpcBj4mIC2gF/klVK/rtaIJEk6uV3354gMvGpzDxnCE9r2D6hypUl5zeg68rdeZLCCRPgDHzOvbgI2J92+6zFRYBYYkQk9g322s/iXh70ugwvxbqy0/Nb6rt3UnktGGsMz2pxPnNScSr+/RVdRXObZie0x71+LwLmNXFeq8Br51lG00nb35SwvHaJr522WhfNyV4qEL14dN78HVlznwJgZSJMPZKjx78ZP8P+IHQ1yeR1pZTJ4CTJ4qaTtO6+dxUC/WHOp5UXI3e7VdCOg1NeXM9pNP8mEQY1r83s9gvcv1MW5uydEMh56YN4VIby+8fqlBVfHoPvv64M7894MddfaoHP3wyRMT4tt3GERoO0QnOqy+0ujqdHOo6nhQ6nzQ6T6sq6jjf1dD9vkZeCPet6Zt2d8NC38+s21dKfmktT355mt2H3xfaA77kE4+Q3+4R8KFOwI+/xgI+WIWGQfQw59UXWl3QUtf1iSK8//9eWej7maXrCxkxNIrrpqb5uin+R9XpdXUeoqkvd+ZLKKROgvHzOw7RhEf7tt0msISGQehQiBrqk91b6PuRfxRXsqmwgu9cN4lwe17tZ1N1fsXaeYimwX0fQUgYpEyCCQvcPfjpMPw8C3gT8Cz0/cjS9YXER4bx5YtG9bxwMFGFyoOn9+AbTjjzQ8KcHvzE69w9+PaAj/Jtu43xAQt9P1FUUc+qT49w35zRxEeF+7o5vtPW5gS8Z7gf2e4R8OFOwE/6/Kkx+FQLeGPaWej7ieUf7idEhLtmZfm6KQOjvgLK8+F4nvNeng/lBVBRcOoWupBwGH4uTFp4agx++HlWQ8aYz2Ch7weq6lv445YiFk4bQdrQABpzbmmAikKPYC9wv+ed6rmDMzyTkA1JY2HM5c4vWtOmQuq5FvDG9JKFvh948eODTsmFOX74Y6y2VueC6slAd4d6eYFzJ42n+BGQNAbOu8kJ+PbXsEznjgdjzFmz/5MGuSZXK89vPMCccclMShukJRdUoe64R6h7vCoKOxboihziBHnmpe5QH+O8J47p3/ozxhjAQn/Qe3NbCWU1Tfx80fm+borzS8QOPXaPV2PVqeVCIyBxtBPm469xh/s45z022S/qkxgTqCz0BzFVZdn6QialDWH22OSB2Wmry7k7przAPQzjcRG1+nDHZYeOcnrqU77kEexjnNohIaED015jTK9Y6A9i6/aWkVdayxNfPr9vSy6oOjXST46vu0P9eB6cOABtLaeWjRrmPMwj+zL3UIy7x5442koRGOOHLPQHsaXrC0kbGsX1U0ec2QaaajrdFdN+C2SBUzCqXWikE+ipE2HS9aeCPWls39VgN8YMChb6g9SnxVV8VFjO/722h5ILrS1O79xzfP24+/3kk5kABIaNcoJ81MUdL6IOTbfhGGOChIX+ILVsg1Ny4ZYZn1Fy4ZMXYdW/OxX72sUkOUE+9spTod4+HGO/SjUm6FnoD0LFJ+p569Mj3DM7u+uSC65mePsR2PIcZM2Babc74+6Jo/vuQRTGmIBkoT8ILf/gAALcdWnW6TNrjsErd0DRJrj0X+CK79kPl4wxXrO0GGSq6ltYseUQC88fwYhhnUouFG2BV74CDZVw829gyhd900hjjN/yqii7iMwXkb0iki8iD3cxP0NE1orIJyLyDxG51mPeI+719orINX3Z+ED00uZD1De3cm/nkgtbX4Dnr3V++HTvuxb4xpgz0mNPX0RCgWeAq4BiYIuIrHQ/DL3dd4BXVPVZETkX5yHqWe7PtwDnASOA90RkvKq29vWBBIImVyu//XA/c8Ylc+4Id8kFVxP87duw9bcwZp7Tw7dxe2PMGfKmpz8DyFfVQlVtBlYAN3RaRoH2wjBDgRL35xuAFarapKr7gXz39kwXVm4robSm6VRhteoj8Pz1TuDP/le4/VULfGPMWfFmTH8k4FkOsRi4uNMy3wfeEZFvALHAlR7rbuq07sjOOxCRJcASgIyMDG/aHXBUlWUbCpl4TjxzxiXDoY+d8fumWvjSC3Dejb5uojEmAHjT0+/q9//a6futwPOqmg5cC/xeREK8XBdVXaqqOaqak5KS4kWTAs/7+8rYd6yWJXOyka2/heevg/AYuPc9C3xjTJ/xpqdfDHj+QiidU8M37e4B5gOo6kciEgUke7muwSm5MCo+lBuKfgzbfgdjr4Kbl0F0gq+bZowJIN709LcA40QkW0QicC7Mruy0zCHgCgARmQREAWXu5W4RkUgRyQbGAZv7qvGBYsfhKgoK8ng1+oeEbvsdXPYtuO2PFvjGmD7XY09fVV0i8gDwNhAKLFfVnSLyGJCrqiuBfwOWichDOMM3d6mqAjtF5BVgF+AC7rc7d063+u03eCvyuyQ1uuDLLzoP9TbGmH4gTjYPHjk5OZqbm+vrZgwMVU68/yvi1n6X6uiRJN39J6fSpTHG9JKIbFXVnJ6W8+rHWaYftDTCm/eTsO4/2KDn0/zV9yzwjTH9zsow+EJVMfxxMZR8wjP6RfInfZ15w4f7ulXGmCBgoT/Q9m+AP90Frib+NuUJfrJlOG99bqyvW2WMCRI2vDNQVGHTs/C7GyAmkea73+P7ezOYPTaZ80YM9XXrjDFBwkJ/ILQ0wOv/BP/7MIyfD/euZuXhOI5VN3HfZaN7Xt8YY/qIDe/0t8pDsOJ2OPopXP5/Yc43URGWrd/GxHPiuWxcsq9baIwJIhb6/anwfWf8vs0Ft66ACfMBWL+vjL3HavjZl85HpKtKFcYY0z9seKc/qMLGX8Lvb4S4VLhv7cnAB1i6voDhQyL5/PkjfNhIY0wwsp5+X2uuh5XfgB2vOr+svfFZiIw/OXvH4So+zC/n4QUTiQizc64xZmBZ6PelEwdgxWI4tgOueNSpgd9p+Oa5DYXERYZx28XBWULaGONbFvp9pWANvHo3aJvzsJNxV562SEllA3/5xxG+emkWQ6LCfdBIY0yws/GFs6UKHz4FL94M8WmwZF2XgQ+w/IP9AHx1dvbAtc8YYzxYT/9sNNfBm/fDztfhvJtg4S8hMq7LRasaWnh58yGun5rGyGHRA9xQY4xxWOifqYpCZ/y+bDdc+QOY9eBp4/eeVmw+RF1p6IwnAAAQOklEQVRz66nn3xpjjA9Y6J+JvPfgtbsBccbvx17xmYs3u9r47YcHmDU2ickjreSCMcZ3bEy/N1Rhw8/gD1+EoaOc8fseAh/gL9tLOFrdaL18Y4zPWU/fW0018MbXYfdKmPxFWPg0RMT2uJqqsmxDIROGx/O58cH50HdjzOBhoe+N8gJYcRsc3wdX/xfMvP8zx+89bcg7zp6jNfzUSi4YYwYBC/2e7HsbXrsPQkLhK6/D6Lm9Wn3ZhkKGD4lkoZVcMMYMAl6N6YvIfBHZKyL5IvJwF/OfEJFt7tc+Ean0mNfqMW9lXza+X7W1wfs/gZe+DAkZzvj96Lm92sTOkio25B3nrkuzreSCMWZQ6LGnLyKhwDPAVUAxsEVEVqrqrvZlVPUhj+W/AUz32ESDqk7ruyYPgMZqeOOfYc9fYcoi+PxTEBHT6808t2E/sRGhVnLBGDNoeNP9nAHkq2qhqjYDK4AbPmP5W4GX+6JxPnE8D567Avb+DeY/Dl9YekaBX1LZwF+2l3DLjAyGRlvJBWPM4OBN6I8Eijy+F7unnUZEMoFsYI3H5CgRyRWRTSJyYzfrLXEvk1tWVuZl0/vBnlWwbB7Ul8Mdb8Il/+z1BdvOfvvhfhT46qysPm2iMcacDW8u5HaVetrNsrcAr6pqq8e0DFUtEZHRwBoR+VRVCzpsTHUpsBQgJyenu233n7Y2WP9jWPcjSJsGX34Rho06481VN7bw8uYirpuSRnpC7/+VYIwx/cWb0C8GPBMwHSjpZtlbgPs9J6hqifu9UETW4Yz3F5y+qo80VsGfvwb7/gbn3wrXPwHhZ1cbZ8XmQ9Q2uVhiz781xgwy3gzvbAHGiUi2iETgBPtpd+GIyAQgAfjIY1qCiES6PycDs4Bdndf1mbK9znBO/ruw4CfOA0/OMvCbXW0s/+AAl46xkgvGmMGnx56+qrpE5AHgbSAUWK6qO0XkMSBXVdtPALcCK1TVc3hmEvBrEWnDOcE87nnXj0/t/gu8/k9OyN+xErJm9clm//oPp+TCj26e0ifbM8aYvuTVj7NUdRWwqtO0Rzt9/34X620EBlf6tbU6Y/frfwIjL4RFv4ehXV6X7jVVZen6QsYPj2OulVwwxgxCwfWL3IZK+PN9kPcOTF8M1/4MwqP6bPMf5DslF37yxalWcsEYMygFT+gf2wV/vB0qi+C6n0PO3Wd8O2Z3lq4vJDU+koXTrOSCMWZwCo7Q3/mGUyEzMg7u+itkXNLnu9hVUs2GvOP8+/wJRIaF9vn2jTGmLwR26Le1wpofwgdPQPpFzvj9kLR+2dVzGwqJiQjl9hmZ/bJ9Y4zpC4Eb+vUV8Nq9ULAaLrwLFvwYwiL7ZVdHqhpYub2EO2ZmMTTGSi4YYwavwAz9ozuc8fuqw3D9k5Dz1X7d3fMfHrCSC8YYvxB4ob/jNXjzAYgcAl9dBaNm9OvuahpbeOnjQ1w7JY1RiVZywRgzuAVO6Le6YPUPYOPTMOoSWPQCxJ/T77tdsbmImiYXS+z5t8YYPxA4oV95ELb8BnLucUoih0X0+y5bWttY/uF+Zo5OYkq6lVwwxgx+gRP6SWPg6x9BwsDdPfPWP45wpKqR/75pcP3o2BhjuhNYz/AbwMBXVX69vpBxqXF8zkouGGP8RGCF/gD6ML+c3UequW/OaEJCrOSCMcY/WOifoaUbCkmJj+SG6VZywRjjPyz0z8DuI9Ws31fGXZdmWckFY4xfsdA/A8vaSy5cnOHrphhjTK9Y6PfSkaoGVm4rYVHOKIbF9P9tocYY05cs9Hvp+Y0HaFPlntnZvm6KMcb0moV+L9Q0tvDSJiu5YIzxXxb6vfDHLe6SC5dZyQVjjH/yKvRFZL6I7BWRfBF5uIv5T4jINvdrn4hUesy7U0Ty3K87+7LxA6mltY3lH+znktGJTE0f5uvmGGPMGemxDIOIhALPAFcBxcAWEVmpqrval1HVhzyW/wYw3f05EfgekAMosNW97ok+PYoBsOrTI5RUNfKfN032dVOMMeaMedPTnwHkq2qhqjYDK4AbPmP5W4GX3Z+vAd5V1Qp30L8LzD+bBvuCqvLr9wsZmxrH3PGpvm6OMcacMW9CfyRQ5PG92D3tNCKSCWQDa3qzrogsEZFcEcktKyvzpt0DamNBObuOVHPfnGwruWCM8WvehH5XKafdLHsL8KqqtvZmXVVdqqo5qpqTkjL4ipctXV9IclwkN07v8lxnjDF+w5vQLwZGeXxPB0q6WfYWTg3t9HbdQWnv0Rre31fGV2dZyQVjjP/zJvS3AONEJFtEInCCfWXnhURkApAAfOQx+W3gahFJEJEE4Gr3NL+xdH0h0eFWcsEYExh6vHtHVV0i8gBOWIcCy1V1p4g8BuSqavsJ4FZghaqqx7oVIvJDnBMHwGOqWtG3h9B/jlY1snL7YW6/ONNKLhhjAoJXT85S1VXAqk7THu30/fvdrLscWH6G7fOp5zceoLXNSi4YYwKH/SK3G7VNLv7w8UEWWMkFY0wAsdDvxorNh6hpdLFkjpVcMMYEDgv9LrS0tvHbDw8wIzuR80dZyQVjTOCw0O/Cqk+PcLiyga9ZYTVjTICx0O9EVVm2oZAxKbFcPsFKLhhjAouFficfFZSz43A1980ZbSUXjDEBx0K/k6UbrOSCMSZwWeh72Hu0hnV7y7jr0kyiwq3kgjEm8Fjoe3huQ3vJhUxfN8UYY/qFhb7bsepG3th2mEU56STEWskFY0xgstB3O1VywW7TNMYELgt93CUXNh1kweQ0MpKs5IIxJnBZ6AN/3FJEdaOLe+dYYTVjTGAL+tB3tbax/IP9zMhKZHpGgq+bY4wx/SroQ3/VjqMcrmxgiZVcMMYEgaAOfVVl6foCRqfEMm+ilVwwxgS+oA79jwqt5IIxJrgEdegvW19IclwEN1nJBWNMkAja0N93rIa1e8u4c2aWlVwwxgQNr0JfROaLyF4RyReRh7tZZpGI7BKRnSLyksf0VhHZ5n6t7GpdX3huQyFR4SEsvsRKLhhjgkePD0YXkVDgGeAqoBjYIiIrVXWXxzLjgEeAWap6QkQ8r4o2qOq0Pm73WSmtbuSNT0q4ZcYoK7lgjAkq3vT0ZwD5qlqoqs3ACuCGTsvcBzyjqicAVLW0b5vZt57feABXWxv3zLYfYxljgos3oT8SKPL4Xuye5mk8MF5EPhSRTSIy32NelIjkuqff2NUORGSJe5ncsrKyXh1Ab9U1uXhx00HmTz6HzKTYft2XMcYMNj0O7wBd3cuoXWxnHDAXSAc2iMhkVa0EMlS1RERGA2tE5FNVLeiwMdWlwFKAnJycztvuU6/kOiUX7ptjP8YyxgQfb3r6xcAoj+/pQEkXy7ypqi2quh/Yi3MSQFVL3O+FwDpg+lm2+Yy5Wtv4zQf7uSgrwUouGGOCkjehvwUYJyLZIhIB3AJ0vgvnDeByABFJxhnuKRSRBBGJ9Jg+C9iFj/xtx1GKTzRYL98YE7R6HN5RVZeIPAC8DYQCy1V1p4g8BuSq6kr3vKtFZBfQCnxLVctF5FLg1yLShnOCedzzrp+B5JRcKGR0cixXThruiyYYY4zPeTOmj6quAlZ1mvaox2cF/tX98lxmIzDl7Jt59j7eX8Gnh6v475umWMkFY0zQCppf5C5dX0hSbARfuMBKLhhjgldQhH7esRrW7CnlDiu5YIwJckER+s9t2E9UeAhfmWklF4wxwS3gQ7+0ppHXPznMly4cRaKVXDDGBLmAD/0XNh6gxUouGGMMEOCh75RcOMT8884hK9lKLhhjTECH/p9yi6hqaOE+e/6tMcYAARz6rtY2nvtgPzmZCVxgJReMMQYI4ND/353ukgvWyzfGmJMCMvRVlWXrC8lOjuUqK7lgjDEnBWTob95fwfbiKu6dk20lF4wxxkNAhv7S9YUkxkZw8wXpvm6KMcYMKgEX+vmlNazeU8odMzOt5IIxxnQScKH/3Ib9RIaFcMfMLF83xRhjBp2ACv3Smkb+/PfDfCkn3UouGGNMFwIq9H+38aC75ILdpmmMMV0JmNCvb3bx+00Hufrc4WRbyQVjjOmSV0/O8gc1jS5mj03mbiusZowx3QqY0B8+JIpnbr/A180wxphBzavhHRGZLyJ7RSRfRB7uZplFIrJLRHaKyEse0+8UkTz3686+argxxpje67GnLyKhwDPAVUAxsEVEVqrqLo9lxgGPALNU9YSIpLqnJwLfA3IABba61z3R94dijDGmJ9709GcA+apaqKrNwArghk7L3Ac80x7mqlrqnn4N8K6qVrjnvQvM75umG2OM6S1vQn8kUOTxvdg9zdN4YLyIfCgim0Rkfi/WRUSWiEiuiOSWlZV533pjjDG94k3od1WxTDt9DwPGAXOBW4HnRGSYl+uiqktVNUdVc1JSUrxokjHGmDPhTegXA6M8vqcDJV0s86aqtqjqfmAvzknAm3WNMcYMEG9CfwswTkSyRSQCuAVY2WmZN4DLAUQkGWe4pxB4G7haRBJEJAG42j3NGGOMD/R4946qukTkAZywDgWWq+pOEXkMyFXVlZwK911AK/AtVS0HEJEf4pw4AB5T1Yr+OBBjjDE9E9XThth9SkTKgINnsYlk4HgfNcdfBNsxB9vxgh1zsDibY85U1R4vig660D9bIpKrqjm+bsdACrZjDrbjBTvmYDEQxxwwBdeMMcb0zELfGGOCSCCG/lJfN8AHgu2Yg+14wY45WPT7MQfcmL4xxpjuBWJP3xhjTDcs9I0xJogETOh7U/M/kIjIchEpFZEdvm7LQBGRUSKyVkR2u5/b8KCv29TfRCRKRDaLyHb3Mf/A120aCCISKiKfiMhffd2WgSIiB0TkUxHZJiK5/bafQBjTd9f834dHzX/gVs+a/4FGRC4DaoHfqepkX7dnIIhIGpCmqn8XkXhgK3BjgP93FiBWVWtFJBz4AHhQVTf5uGn9SkT+Fec5HENU9Xpft2cgiMgBIEdV+/UHaYHS0/em5n9AUdX1QFCVtFDVI6r6d/fnGmA3XZTqDiTqqHV/DXe//L+n9hlEJB24DnjO120JRIES+l7V7TeBQ0SygOnAx75tSf9zD3VsA0pxHkoU6Mf8JPDvQJuvGzLAFHhHRLaKyJL+2kmghL5XdftNYBCROOA14P+oarWv29PfVLVVVafhlCafISIBO5wnItcDpaq61ddt8YFZqnoBsAC43z2E2+cCJfStbn+QcI9rvwb8QVX/7Ov2DCRVrQTWEdiPHJ0FLHSPb68A5onIi75t0sBQ1RL3eynwOs6wdZ8LlND3pua/8XPui5q/AXar6s993Z6BICIp7qfQISLRwJXAHt+2qv+o6iOqmq6qWTj/H69R1cU+bla/E5FY980JiEgszrNH+uXOvIAIfVV1Ae01/3cDr6jqTt+2qn+JyMvAR8AEESkWkXt83aYBMAv4Ck7vb5v7da2vG9XP0oC1IvIPnM7Nu6oaNLcxBpHhwAcish3YDLylqv/bHzsKiFs2jTHGeCcgevrGGGO8Y6FvjDFBxELfGGOCiIW+McYEEQt9Y4wJIhb6xhgTRCz0jTEmiPx/Sgj2pSqHbb8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################Feedforward Neural Network###################################\n",
    "daf= {'post':Dataset['Requirement'],'tags':Dataset['Type']}\n",
    "df = pd.DataFrame(daf)\n",
    "my_tags = ['O&M','Design','Construction']\n",
    "df = df[pd.notnull(df['tags'])]\n",
    "# print(df.head(10))\n",
    "# print(df['post'].apply(lambda x: len(x.split(' '))).sum())\n",
    "df = shuffle(df)\n",
    "df = shuffle(df)\n",
    "df = shuffle(df)\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 70\n",
    "epochs = 6\n",
    "\n",
    "train_posts, test_posts, train_tags,  test_tags = train_test_split(df['post'], df['tags'], test_size=0.3, random_state=40)\n",
    "\n",
    "#train_size = int(len(df) * .75)\n",
    "#train_posts = df['post'][:train_size]\n",
    "#train_tags = df['tags'][:train_size]\n",
    "#\n",
    "#test_posts = df['post'][train_size:]\n",
    "#test_tags = df['tags'][train_size:]\n",
    "\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "Types_List = ['Design','Construction','O&M']\n",
    "accr = model.evaluate(x_test,y_test)\n",
    "#np.argmax(y_pred, axis=1)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "y_pred = model.predict(x_test)\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1),target_names=Types_List))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.59329390525818\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy Score ->  81.16308470290771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Design       0.71      0.71      0.71       185\n",
      "Construction       0.83      0.88      0.85       413\n",
      "         O&M       0.88      0.77      0.82       193\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       791\n",
      "   macro avg       0.81      0.78      0.79       791\n",
      "weighted avg       0.81      0.81      0.81       791\n",
      "\n",
      "[[131  45   9]\n",
      " [ 39 363  11]\n",
      " [ 15  30 148]]\n"
     ]
    }
   ],
   "source": [
    "#################################For N-gram Based Text Classification##############################\n",
    "\n",
    "from sklearn import model_selection\n",
    "my_types = ['Design','Construction','O&M']\n",
    "   \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(Dataset['Requirement'],Dataset['Type'],test_size=0.3, random_state=49)\n",
    "      \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,1), max_features=5000)\n",
    "tfidf_vect_ngram.fit(Dataset['Requirement'])\n",
    "X_train_Tfidf =  tfidf_vect_ngram.transform(X_train)\n",
    "X_test_Tfidf =  tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train_Tfidf,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_DT = model.predict(X_test_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"DT Accuracy Score -> \",accuracy_score(predictions_DT, y_test)*100)\n",
    "print(classification_report(y_test, predictions_DT,target_names=my_types))\n",
    "print(confusion_matrix(y_test, predictions_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
